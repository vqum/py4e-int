<?xml version="1.0"?>
<section xml:id="viz_visualizing-networks-and-interconnections">
  <title>Visualizing networks and interconnections</title>
  <p>In this application, we will perform some of the functions of a search
            engine. We will first spider a small subset of the web and run a
            simplified version of the Google page rank algorithm to determine which
            pages are most highly connected, and then visualize the page rank and
            connectivity of our small corner of the web. We will use the D3
            JavaScript visualization library <url href="http://d3js.org/" visual="http://d3js.org/">http://d3js.org/</url> to produce the
            visualization output.</p>
  <p>You can download and extract this application from:</p>
  <p>
    <url href="http://www.py4e.com/code3/pagerank.zip" visual="http://www.py4e.com/code3/pagerank.zip">www.py4e.com/code3/pagerank.zip</url>
  </p>
  <image source="images/pagerank.png" width="50%" alt="A Page Ranking"/>
  <p>The first program (<em>spider.py</em>) program crawls a web site
            and pulls a series of pages into the database
            (<em>spider.sqlite</em>), recording the links between pages. You
            can restart the process at any time by removing the
            <em>spider.sqlite</em> file and rerunning
            <em>spider.py</em>.</p>
  <pre>Enter web url or enter: http://www.dr-chuck.com/
['http://www.dr-chuck.com']
How many pages:2
1 http://www.dr-chuck.com/ 12
2 http://www.dr-chuck.com/csev-blog/ 57
How many pages:</pre>
  <p>In this sample run, we told it to crawl a website and retrieve two
            pages. If you restart the program and tell it to crawl more pages, it
            will not re-crawl any pages already in the database. Upon restart it
            goes to a random non-crawled page and starts there. So each successive
            run of <em>spider.py</em> is additive.</p>
  <pre>Enter web url or enter: http://www.dr-chuck.com/
['http://www.dr-chuck.com']
How many pages:3
3 http://www.dr-chuck.com/csev-blog 57
4 http://www.dr-chuck.com/dr-chuck/resume/speaking.htm 1
5 http://www.dr-chuck.com/dr-chuck/resume/index.htm 13
How many pages:</pre>
  <p>You can have multiple starting points in the same database&#x2014;within the
            program, these are called <q>webs</q>. The spider chooses randomly amongst
            all non-visited links across all the webs as the next page to spider.</p>
  <p>If you want to dump the contents of the <em>spider.sqlite</em>
            file, you can run <em>spdump.py</em> as follows:</p>
  <pre>(5, None, 1.0, 3, 'http://www.dr-chuck.com/csev-blog')
(3, None, 1.0, 4, 'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')
(1, None, 1.0, 2, 'http://www.dr-chuck.com/csev-blog/')
(1, None, 1.0, 5, 'http://www.dr-chuck.com/dr-chuck/resume/index.htm')
4 rows.</pre>
  <p>This shows the number of incoming links, the old page rank, the new page
            rank, the id of the page, and the url of the page. The
            <em>spdump.py</em> program only shows pages that have at least
            one incoming link to them.</p>
  <p>Once you have a few pages in the database, you can run page rank on the
            pages using the <em>sprank.py</em> program. You simply tell it
            how many page rank iterations to run.</p>
  <pre>How many iterations:2
1 0.546848992536
2 0.226714939664
[(1, 0.559), (2, 0.659), (3, 0.985), (4, 2.135), (5, 0.659)]</pre>
  <p>You can dump the database again to see that page rank has been updated:</p>
  <pre>(5, 1.0, 0.985, 3, 'http://www.dr-chuck.com/csev-blog')
(3, 1.0, 2.135, 4, 'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')
(1, 1.0, 0.659, 2, 'http://www.dr-chuck.com/csev-blog/')
(1, 1.0, 0.659, 5, 'http://www.dr-chuck.com/dr-chuck/resume/index.htm')
4 rows.</pre>
  <p>You can run <em>sprank.py</em> as many times as you like and it
            will simply refine the page rank each time you run it. You can even run
            <em>sprank.py</em> a few times and then go spider a few more
            pages sith <em>spider.py</em> and then run
            <em>sprank.py</em> to reconverge the page rank values. A search
            engine usually runs both the crawling and ranking programs all the time.</p>
  <p>If you want to restart the page rank calculations without respidering
            the web pages, you can use <em>spreset.py</em> and then restart
            <em>sprank.py</em>.</p>
  <pre>How many iterations:50
1 0.546848992536
2 0.226714939664
3 0.0659516187242
4 0.0244199333
5 0.0102096489546
6 0.00610244329379
...
42 0.000109076928206
43 9.91987599002e-05
44 9.02151706798e-05
45 8.20451504471e-05
46 7.46150183837e-05
47 6.7857770908e-05
48 6.17124694224e-05
49 5.61236959327e-05
50 5.10410499467e-05
[(512, 0.0296), (1, 12.79), (2, 28.93), (3, 6.808), (4, 13.46)]</pre>
  <p>For each iteration of the page rank algorithm it prints the average
            change in page rank per page. The network initially is quite unbalanced
            and so the individual page rank values change wildly between iterations.
            But in a few short iterations, the page rank converges. You should run
            <em>sprank.py</em> long enough that the page rank values
            converge.</p>
  <p>If you want to visualize the current top pages in terms of page rank,
            run <em>spjson.py</em> to read the database and write the data
            for the most highly linked pages in JSON format to be viewed in a web
            browser.</p>
  <pre>Creating JSON output on spider.json...
How many nodes? 30
Open force.html in a browser to view the visualization</pre>
  <p>You can view this data by opening the file <em>force.html</em>
            in your web browser. This shows an automatic layout of the nodes and
            links. You can click and drag any node and you can also double-click on
            a node to find the URL that is represented by the node.</p>
  <p>If you rerun the other utilities, rerun <em>spjson.py</em> and
            press refresh in the browser to get the new data from
            <em>spider.json</em>.</p>
</section>
