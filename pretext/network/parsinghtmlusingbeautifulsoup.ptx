<?xml version="1.0"?>
<section xml:id="network_parsing-html-using-beautifulsoup">
  <title>Parsing HTML using BeautifulSoup</title>
  <p>Even though HTML looks like XML and some pages are carefully
            constructed to be XML, most HTML is generally broken in ways that cause
            an XML parser to reject the entire page of HTML as improperly formed.</p>
  <note>
    <p>The XML format is described in the next chapter.</p>
  </note>
  <p>There are a number of Python libraries which can help you parse HTML and
            extract data from the pages. Each of the libraries has its strengths and
            weaknesses and you can pick one based on your needs.</p>
  <p>As an example, we will simply parse some HTML input and extract links
            using the <em>BeautifulSoup</em> library. BeautifulSoup tolerates highly flawed
            HTML and still lets you easily extract the data you need. You can download and
            install the BeautifulSoup code from:</p>
  <p>
    <url href="https://pypi.python.org/pypi/beautifulsoup4" visual="https://pypi.python.org/pypi/beautifulsoup4">https://pypi.python.org/pypi/beautifulsoup4</url>
  </p>
  <p>Information on installing BeautifulSoup with the Python Package Index tool <c>pip</c>
            is available at:</p>
  <p>
    <url href="https://packaging.python.org/tutorials/installing-packages/" visual="https://packaging.python.org/tutorials/installing-packages/">https://packaging.python.org/tutorials/installing-packages/</url>
  </p>
  <p>We will use <c>urllib</c> to read the page and then use
            <c>BeautifulSoup</c> to extract the <c>href</c> attributes
            from the anchor (<c>a</c>) tags.</p>
  <program xml:id="urllinks" interactive="activecode" language="python3">
    <input>
import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup
import ssl

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = "https://docs.python.org"
html = urllib.request.urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, 'html.parser')

# Retrieve all of the anchor tags
tags = soup('a')
for tag in tags:
    print(tag.get('href', None))
        </input>
  </program>
  <p>The program prompts for a web address, then opens the web page, reads
            the data and passes the data to the BeautifulSoup parser, and then
            retrieves all of the anchor tags and prints out the <c>href</c>
            attribute for each tag.</p>
  <p>This list is much longer because some HTML anchor tags are relative
            paths (e.g., tutorial/index.html) or in-page references (e.g., &#x2018;#')
            that do not include <q><url href="http://" visual="http://">http://</url></q> or <q><url href="https://" visual="https://">https://</url></q>, which was a
            requirement in our regular expression.</p>
  <p>You can use also BeautifulSoup to pull out various parts of each tag:</p>
  <program xml:id="urllink2" interactive="activecode" language="python3">
    <input>
from urllib.request import urlopen
from bs4 import BeautifulSoup
import ssl

# Ignore SSL certificate errors
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE

url = "http://www.dr-chuck.com/page1.htm"
html = urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, "html.parser")

# Retrieve all of the anchor tags
tags = soup('a')
for tag in tags:
    # Look at the parts of a tag
    print('TAG:', tag)
    print('URL:', tag.get('href', None))
    print('Contents:', tag.contents[0])
    print('Attrs:', tag.attrs)
        </input>
  </program>
  <p><c>html.parser</c> is the HTML parser included in the standard Python 3 library.
            Information on other HTML parsers is available at:</p>
  <p>
    <url href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser" visual="http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser">http://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser</url>
  </p>
  <p>These examples only begin to show the power of BeautifulSoup when it
            comes to parsing HTML.</p>
</section>
